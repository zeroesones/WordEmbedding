def check_values(row):
    if pd.notna(row['C']):
        values = row['C'].split()
        values = [float(v) / 1000 for v in values if v != 'NaN']
        return any(np.isclose(values, row['D'], atol=1e-6))
    return False


import pandas as pd
import numpy as np

# Sample data
data = {'C': ['0.5 1.2 3.0', '2.5', '1.0', np.nan],
        'D': [12, 25, 10, 20]}
df = pd.DataFrame(data)

# Function to check if any value in C matches with D
def check_match(row, col_c, col_d):
    if pd.notna(row[col_c]):
        c_value = row[col_c]
        if isinstance(c_value, str):
            values = c_value.split()
            for val in values:
                if pd.notna(val):
                    try:
                        float_val = float(val) / 1000
                        if np.isclose(float_val, row[col_d]):
                            return True
                    except ValueError:
                        pass
        else:
            try:
                float_val = float(c_value) / 1000
                if np.isclose(float_val, row[col_d]):
                    return True
            except ValueError:
                pass
    return False

# Columns to compare
col_c = 'C'
col_d = 'D'

# Apply the function to each row and create a new column 'Result'
df['Result'] = df.apply(lambda row: check_match(row, col_c, col_d), axis=1)

print(df)




import pandas as pd
import numpy as np

# Sample data
data = {'C': ['0.5 1.2 3.0', '2.5', '1.0', np.nan],
        'D': [12, 25, 10, 20]}
df = pd.DataFrame(data)

# Function to check if any value in C matches with D
def check_match(row, col_c, col_d):
    if pd.notna(row[col_c]):
        if isinstance(row[col_c], str):
            values = row[col_c].split()
        else:
            values = [str(row[col_c])]
        for val in values:
            if pd.notna(val):
                try:
                    float_val = float(val) / 1000
                    if np.isclose(float_val, row[col_d]):
                        return True
                except ValueError:
                    pass
    return False

# Columns to compare
col_c = 'C'
col_d = 'D'

# Apply the function to each row and create a new column 'Result'
df['Result'] = df.apply(lambda row: check_match(row, col_c, col_d), axis=1)

print(df)




import pandas as pd
import numpy as np

# Sample data
data = {'C': ['0.5 1.2 3.0', '2.5', '1.0', np.nan],
        'D': [12, 25, 10, 20]}
df = pd.DataFrame(data)

# Function to check if any value in C matches with D
def check_match(row, col_c, col_d):
    if pd.notna(row[col_c]):
        values = row[col_c].split()
        for val in values:
            if pd.notna(val):
                try:
                    float_val = float(val) / 1000
                    if np.isclose(float_val, row[col_d]):
                        return True
                except ValueError:
                    pass
    return False

# Columns to compare
col_c = 'C'
col_d = 'D'

# Apply the function to each row and create a new column 'Result'
df['Result'] = df.apply(lambda row: check_match(row, col_c, col_d), axis=1)

print(df)





Certainly! You can remove the commas from the text before applying the regular expression. Additionally, you can update the regular expression to account for the optional space between the currency and the amount. Here's the updated code:

```python
import pandas as pd
import re

# Sample dataframe
data = {'date': ['2021-01-01', '2021-01-02'],
        'id': [1, 2],
        'dogref': ['ref1', 'ref2'],
        'text': ['minimum transfer amount with respect to Party A, USD 10,000',
                 'minimum transfer amount with respect to Party A and Party B $20,000']}

df = pd.DataFrame(data)

# Function to extract currency and amount
def extract_currency_amount(text):
    text = text.replace(",", "")  # Remove commas
    match = re.search(r'(?:[A-Za-z]{3}|\$|€|£)\s*(\d{1,3}(?:[\.]\d{0,2})?)', text)
    if match:
        currency = match.group(1).strip()
        amount = match.group(2)
        return currency, float(amount)
    return None, None

# Apply the function and create new columns
df['currency'], df['amount'] = zip(*df['text'].apply(extract_currency_amount))

print(df)
```

This updated code should meet your new conditions:

- Commas are removed from the text before applying the regex.
- The regex allows for an optional space between the currency and the amount.


o account for the possibility of a space or no space between the currency symbol and the amount, you can update the regular expression pattern. The "\s?" denotes that there can be zero or one whitespace character. Here's how you can modify the code:

```python
import pandas as pd
import re

# Sample DataFrame (you would use your real DataFrame here)
data = {
    'MID': [1, 2],
    'DOCREFID': ['Doc1', 'Doc2'],
    'AGREEMENT CONTENT': [
        'MINIMUM TRANSFER AMOUNT means with respect to a party as of any date USD $100,000.',
        'MINIMUM TRANSFER AMOUNT means with respect to a party as of any date EUR€50,000.'
    ]
}

df = pd.DataFrame(data)

# Initialize new columns
df['Extracted_Phrase'] = ''

# Regular expression pattern to match the relevant phrases
pattern = r"(MINIMUM TRANSFER AMOUNT means with respect to a party as of any date [\w\$€£¥]\s?[\d,]+)"

def extract_phrase(row):
    match = re.search(pattern, row['AGREEMENT CONTENT'], re.IGNORECASE)
    if match:
        row['Extracted_Phrase'] = match.group(0)
    return row

# Apply the function to each row
df = df.apply(extract_phrase, axis=1)

print(df)
```

In this updated pattern, the "\s?" will match either a space or no space between the currency symbol and the amount, catering to both scenarios.






If you prefer to store multiple values separated by spaces in the same cell rather than as lists, you can adapt the code to concatenate the extracted values into strings. Here's how you can do it:

```python





import pandas as pd
import re

# Sample DataFrame
data = {
    'Primary Key': [1, 2],
    'Reference Number': ['Ref1', 'Ref2'],
    'Actual Text': [
        "Some text here and 'minimum net asset amount' with subject to party A. Another 'minimum net asset amount' with subject to party B, USD $30,000.",
        '"minimum net asset amount" with respect to party A and party B, USD $20,000. Also, minimum net asset amount with respect to party B, €25,000.'
    ]
}

df = pd.DataFrame(data)

# Initialize empty columns with default empty strings
df['Patterns'] = ''
df['Parties'] = ''
df['Additional Parties'] = ''
df['Currencies'] = ''
df['Amounts'] = ''

# Regular expression pattern
pattern = r"(['\"]?)minimum net asset amount(['\"]?) (?:with (?:subject to|respect to) )?party ([A,B])(?: and party ([A,B]))?,? ([\w\$\€\£\¥]{1,4})?\s?([\d,]+)?"

def extract_info(row):
    matches = re.findall(pattern, row['Actual Text'], re.IGNORECASE)
    
    for match in matches:
        row['Patterns'] += ' '.join(match) + ' '
        row['Parties'] += match[3] + ' '
        row['Additional Parties'] += (match[4] + ' ') if match[4] else ''
        row['Currencies'] += (match[5].strip() + ' ') if match[5].strip() else 'USD '
        row['Amounts'] += match[6].replace(',', '') + ' ' if match[6] else ''

    return row

# Apply the function to each row
df = df.apply(extract_info, axis=1)

# Trim the trailing spaces
for col in ['Patterns', 'Parties', 'Additional Parties', 'Currencies', 'Amounts']:
    df[col] = df[col].str.rstrip()

print(df)
```

In this version, the new columns "Patterns", "Parties", "Additional Parties", "Currencies", and "Amounts" contain strings that hold all relevant extracted values for each row in the DataFrame, separated by spaces. After processing, the code also trims any trailing spaces.





To accomplish this, you can modify the regular expression pattern and the Python code to tag the amount based on whether it's for party A, party B, or both. You'll need to capture the party (either "A" or "B") mentioned in the phrase and use it to tag the amount accordingly.

Here's the updated code:

```python
import re

def extract_phrases(text):
    pattern = r"(['\"]?)minimum net asset amount(['\"]?) (?:with (?:subject to|respect to) )?party ([A,B])(?: and party ([A,B]))?,? ([\w\$\€\£\¥]{1,4})?\s?([\d,]+)?"
    matches = re.findall(pattern, text, re.IGNORECASE)

    for match in matches:
        full_match = ''.join(match)
        print("Found:", full_match)

        party = match[3]  # Party A or B
        additional_party = match[4]  # If there's a second party mentioned
        currency = match[5].strip() if match[5].strip() else 'USD'  # Default to USD if not specified
        amount = match[6].replace(',', '')  # Removing commas for easier parsing

        # Determine party tag
        if additional_party:
            tag = f"Amount common to party {party} and party {additional_party}"
        else:
            tag = f"Amount specific to party {party}"

        print(tag)
        print(f"Currency: {currency}")
        print(f"Amount: {amount}")

# Sample data
sample_text = """
Page 1: Some text here and 'minimum net asset amount' with subject to party A.
Page 2: Another text, "minimum net asset amount" with respect to party A and party B, USD$20,000.
Page 3: Yet another text, minimum net asset amount with respect to party A, $45,000.
Page 4: In Europe, minimum net asset amount with respect to party B, €25,000.
"""

extract_phrases(sample_text)
```

In this updated code, I modified the regular expression to capture the party (either "A" or "B") using `party ([A,B])(?: and party ([A,B]))?,?`. Then, within the Python code, I use these captured values to determine if the amount is specific to party A, party B, or common to both, and tag it accordingly.



import pandas as pd
import re
from datetime import datetime
import datefinder

# Sample data
data = {'ContractDate': ['Agreement dated as o May 19, 2008',
                         'Master Agreement dated as of 9th July 2004',
                         'Agreement A dated as o 10th July 2008 B dated as of 10 October 2022 C dated as o October 312008',
                         'Amendment dated as of January 24, 20! 8']}
df = pd.DataFrame(data)

# Function to extract and clean dates
def extract_clean_date(text):
    # Remove noise characters
    cleaned_text = re.sub(r'20! 8', '2018', text)
    cleaned_text = re.sub(r'[^0-9a-zA-Z\s]', '', cleaned_text)
    
    # Replace '20! 8' with '2018'
    
    print(cleaned_text)

    # Use datefinder to extract dates
    matches = list(datefinder.find_dates(cleaned_text, strict=True))
    print(matches)
    if matches:
        # Get the first matched date and format it
        extracted_date = matches[0]
        return extracted_date.strftime('%Y-%m-%d')
    
    return None

# Apply the function to the 'ContractDate' column
df['CleanedDate'] = df['ContractDate'].apply(extract_clean_date)

# Display the cleaned dates
print(df)
